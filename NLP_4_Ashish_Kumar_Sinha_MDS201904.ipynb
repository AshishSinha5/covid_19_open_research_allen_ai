{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ashish Kumar Sinha\n",
    "### MDS201904\n",
    "### NLP-ASSN-4\n",
    "Reference - https://github.com/spro/practical-pytorch/blob/master/char-rnn-generation/char-rnn-generation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ashis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langid in c:\\users\\ashis\\anaconda3\\lib\\site-packages (1.1.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from langid) (1.18.1)\n",
      "Requirement already satisfied: in_place in c:\\users\\ashis\\anaconda3\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: jaraco.windows; sys_platform == \"win32\" and python_version < \"3.8\" and platform_python_implementation != \"PyPy\" in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from in_place) (5.5.0)\n",
      "Requirement already satisfied: jaraco.collections in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from jaraco.windows; sys_platform == \"win32\" and python_version < \"3.8\" and platform_python_implementation != \"PyPy\"->in_place) (3.3.0)\n",
      "Requirement already satisfied: jaraco.structures>=1.1.1 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from jaraco.windows; sys_platform == \"win32\" and python_version < \"3.8\" and platform_python_implementation != \"PyPy\"->in_place) (2.1.0)\n",
      "Requirement already satisfied: jaraco.text in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from jaraco.windows; sys_platform == \"win32\" and python_version < \"3.8\" and platform_python_implementation != \"PyPy\"->in_place) (3.5.0)\n",
      "Requirement already satisfied: path in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from jaraco.windows; sys_platform == \"win32\" and python_version < \"3.8\" and platform_python_implementation != \"PyPy\"->in_place) (13.1.0)\n",
      "Requirement already satisfied: jaraco.ui in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from jaraco.windows; sys_platform == \"win32\" and python_version < \"3.8\" and platform_python_implementation != \"PyPy\"->in_place) (2.3.0)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from jaraco.windows; sys_platform == \"win32\" and python_version < \"3.8\" and platform_python_implementation != \"PyPy\"->in_place) (8.2.0)\n",
      "Requirement already satisfied: jaraco.classes in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from jaraco.collections->jaraco.windows; sys_platform == \"win32\" and python_version < \"3.8\" and platform_python_implementation != \"PyPy\"->in_place) (3.2.1)\n",
      "Requirement already satisfied: jaraco.functools in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from jaraco.text->jaraco.windows; sys_platform == \"win32\" and python_version < \"3.8\" and platform_python_implementation != \"PyPy\"->in_place) (3.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.5; python_version < \"3.8\" in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from path->jaraco.windows; sys_platform == \"win32\" and python_version < \"3.8\" and platform_python_implementation != \"PyPy\"->in_place) (1.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.5; python_version < \"3.8\"->path->jaraco.windows; sys_platform == \"win32\" and python_version < \"3.8\" and platform_python_implementation != \"PyPy\"->in_place) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import fileinput\n",
    "import collections\n",
    "\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "import pickle\n",
    "import csv\n",
    "import operator\n",
    "import random\n",
    "import math\n",
    "from time import time\n",
    "import logging\n",
    "# from numba import jit, cuda\n",
    "from IPython.display import Image\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "import gensim.models\n",
    "from gensim.utils import lemmatize\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "\n",
    "#import spacy\n",
    "#from spacy_langdetect import LanguageDetector\n",
    "#nlp = spacy.load('en')\n",
    "#nlp.add_pipe(LanguageDetector(), name='language_detector', last=True)\n",
    "\n",
    "! pip install langid\n",
    "import langid\n",
    "\n",
    "import gc\n",
    "\n",
    "! pip install in_place\n",
    "import in_place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import linecache\n",
    "import itertools\n",
    "\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_data(file_path, corpus_prop = 0.5):\n",
    "    \"\"\"\n",
    "    args : file_path : path of file for preprocessed corpus\n",
    "    returns : splits raw text to train and test set\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    1 - count the number of lines\n",
    "    2 - |train_set| = train_prop * number_of_lines\n",
    "    \"\"\"\n",
    "    \n",
    "    train_file = 'data/train_preprocessed.txt'\n",
    "    print('getting line count')\n",
    "    with open(file_path, 'r', encoding = 'utf-8') as f:\n",
    "        for i, l in tqdm(enumerate(f)):\n",
    "            pass\n",
    "    num_lines =  i + 1\n",
    "    print('Number of lines = {}'.format(num_lines))\n",
    "    print('building train set using only {} % of the entire corpus'.format(corpus_prop*100))\n",
    "    f1 = open(train_file, 'w', encoding = 'utf-8')\n",
    "    with open(file_path, 'r', encoding = 'utf-8') as f:\n",
    "        for i, l in tqdm(enumerate(f)):\n",
    "            if i < (num_lines*corpus_prop):\n",
    "                f1.write(l)\n",
    "    with open(train_file, 'r', encoding = 'utf-8') as f:\n",
    "        for i, l in tqdm(enumerate(f)):\n",
    "            pass\n",
    "    print(\"Number of sentences in train set = {}\".format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85283it [00:00, 846647.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting line count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8374537it [00:07, 1050974.05it/s]\n",
      "41631it [00:00, 413279.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines = 8374537\n",
      "building train set using only 50.0 % of the entire corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8374537it [00:12, 647078.73it/s] \n",
      "4187269it [00:03, 1097007.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in train set = 4187269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = 'data/preprocessed.txt'\n",
    "make_train_data(file_path, corpus_prop=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make inputs out of this big string of data, we will be splitting it into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class text_generator:\n",
    "    # a text generator class to generate text iteratively\n",
    "    def __init__(self,file_path, file_len, chunk_size):\n",
    "        self.file_path = file_path\n",
    "        self.chunk_size = chunk_size\n",
    "        self.file_len = file_len\n",
    "    \n",
    "    def random_chunk(self):\n",
    "        start_index = random.randint(0, self.file_len - self.chunk_size)\n",
    "        end_index = start_index + self.chunk_size + 1\n",
    "        lines = \"\"\n",
    "        \"\"\"for i in range(start_index,end_index):\n",
    "            line = linecache.getline(self.file_path, i)\n",
    "            l = \"\"\n",
    "            for j in line:\n",
    "                # removing all charecter not in all_charecters\n",
    "                if j in all_characters:\n",
    "                    l+=j\n",
    "            lines += l\"\"\"\n",
    "        with open(self.file_path, \"r\", encoding='utf-8') as text_file:\n",
    "            for line in itertools.islice(text_file, start_index, end_index):\n",
    "                l = \"\"\n",
    "                for j in line:\n",
    "                    # removing all charecter not in all_charecters\n",
    "                    if j in all_characters:\n",
    "                        l+=j\n",
    "                lines += l\n",
    "        text_file.close()\n",
    "        return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'data/train_preprocessed.txt'\n",
    "train_len = 4187269\n",
    "chunk_size = 50\n",
    "text_generator = text_generator(train_file, train_len, chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'these include malaria travellers diarrhoea sexually transmitted infections and rtas\\nhealth hazards that are rare should be put into perspective and discussed based on the individual travellers risk profile\\ncurrent best practice emphasizes the need for a patientcentred approach and shared decisionmaking\\ntherefore for each risk the travel medicine practitioner must balance the need for prophylaxis against the realistic risk of infection and the likelihood of adherence to preventive measures by the traveller\\nthe latter depends on a number of factors including perception of risk concerns about available preventive measures and treatments and preferred risk management options\\ntravellers should know that no intervention is fully protective\\nmalaria is one of the most common and serious causes of fever in travellers occurring while abroad or on return\\nthe risk of malaria is greatest in subsaharan africa intermediate in south asia and lowest in central and south america and southeast asia\\nhowever the risk for acquiring malaria can vary widely from traveller to traveller from region to region and within countries\\nthose at particular risk of disease acquisition are longterm vfr travellers while those at risk of severe disease are pregnant women travellers with complex comorbidities and elderly individuals\\nprevention of infection involves understanding the disease process and the abcd of malariaawareness of risk bite prevention from nocturnal anopheles spp\\nmosquitoes chemoprophylaxis prompt diagnosis of infection\\nhealth risk assessment bite prevention measures include use of insect repellent such as deet covering up during the highest risk time periods and sleeping under an insecticideimpregnated mosquito net if enclosed and screened accommodation is not available\\nthe choice of chemoprophylaxis depends on the type of malaria that is endemic in the region being visited and whether drug resistance is present\\nit also depends on individual factors and preferences for the different drug regimens such as dosing frequency and affordability\\nfor countries with a high prevalence of chloroquineresistant p. falciparum mefloquine doxycycline or atovaquoneeproguanil can be taken\\nfor the limited areas with little chloroquine resistance chloroquine plus proguanil should be taken and in areas without resistance chloroquine alone can be used\\npractitioners should be aware of the adverse effects of and contraindications to all the antimalarials\\nfor detailed information including adverse effects and special situations such as pregnancy see the uk malaria guidelines at linesfortravellersfromtheuk\\ntravellers should be advised that although malaria prevention methods are highly effective they do not provide protection and they should seek immediate medical attention if they have symptoms suggestive of infection\\ndiarrhoea is the most common illness affecting travellers to developing countries with 20e60 being affected\\nit can cause significant morbidity and can result in loss of travel time amendment of itineraries and medical encounters including hospitalization\\ntravellers diarrhoea is usually nonbloody watery may be frequent and explosive but has minimal or no fever\\ntable prevention of malaria awareness of risk mefloquine a a 20e50 concentration is usually recommended and is safe for all travellers months of age manufacturers guidelines for use should be followed\\nb before prescribing an antimalarial agent the prevalence species and potential resistance of malaria found in the travel destination must be determined as should any medical contraindications\\nthe most common causal organisms are bacteria particularly enterotoxigenic escherichia coli enteroaggregative e. coli salmonella spp\\ncampylobacter and shigella but viruses and protozoa can also be the cause\\nrarer but more serious are the enteric fevers which have the same risk factors as other gastrointestinal infections\\ntravellers can be concerned about the risk of cholera but apart from a few specific circumstances this poses little threat to most travellers\\nthe travel health practitioner should discuss both prevention and selftreatment\\nprevention advice should focus on food and water hygiene and it is useful to emphasize the boil it cook it peel it or forget it approach to eating while abroad\\nthe importance of hand hygiene should also be stressed however it is not always easy to follow this advice and illness can still occur despite adhering to it\\nprophylaxis with antibiotics is recommended in limited circumstances\\nguidelines on selftreatment should stress the importance of maintaining hydration and advise when to control symptoms with an antimotility agent and when to treat illness with a short course of antibiotics\\nmild diarrhoea should only require increased hydration and possibly an antimotility agent but antibiotics may be advised for moderate diarrhoea and should be used if it is severe\\nselfadministered fluoroquinolone antibiotics or a macrolide significantly reduce the duration and severity of symptoms in acute watery diarrhoea\\na single dose of ciprofloxacin or levofloxacin can be sufficient in many cases if taken soon after the onset of symptoms but treatment can be continued for up to days if diarrhoea persists\\nin areas where fluoroquinoloneresistant campylobacter is widespread azithromycin is the drug of choice\\nhowever owing to its proarrhythmogenic properties it should be avoided in elderly travellers with cardiovascular disease\\nfor moderate diarrhoea the combination of antibiotic and loperamide is more effective in reducing both the duration and severity of symptoms compared with antibiotics alone\\nhowever an antimotility agent is not advised if the diarrhoea is dysenteric or if the person is febrile\\npackaged oral rehydration salts can be used to maintain hydration in infants young children and the elderly\\nmedical advice should be sought abroad if symptoms continue or if the diarrhoea is dysenteric\\ntravellers with persistent diarrhoea on return from their trip should undergo further investigations particularly looking for protozoan infection with giardia intestinalis or cryptosporidium\\ntravellers and tourists often engage in risky behaviour when abroad and may have unprotected sexual intercourse with other travellers or locals from highrisk populations\\nstudies have found that 25e30 of people with a confirmed sti attending a genitourinary medicine clinic reported a new partner while away with 60e70 not using or inconsistently using condoms\\nthe risk of transmission of stis and hiv should be discussed with all travellers who seek pretravel advice as the risk can be virtually eliminated by practising safer sex\\nraising awareness of these sensitive issues is an important part of the travel health consultation although some practitioners find them difficult to address\\nless common risk factors for hiv infection include invasive medical treatment and transfusion with contaminated blood which are of particular importance in subsaharan africa where the seroprevalence of hiv can approach\\nvaccinations vaccinepreventable diseases are uncommon to rare in travellers\\nthe decision to vaccinate a traveller is based on the epidemiology and risk of the disease the effectiveness of the vaccine the risk of vaccineassociated adverse events the individuals underlying health the cost of vaccination and the ability to employ other diseasepreventing measures\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generator.random_chunk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model\n",
    "We are using PyTorch for our implementation <br>\n",
    "This model will take as input the character for step $t_{-1}$ and is expected to output the next character $t$. There are three layers - one linear layer that encodes the input character into an internal state, one GRU layer (which may itself have multiple layers) that operates on that internal state and a hidden state, and a decoder layer that outputs the probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs and Targets\n",
    "\n",
    "Each chunk will be turned into a tensor, specifically a LongTensor (used for integer values), by looping through the characters of the string and looking up the index of each character in all_characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 11, 12, 39, 40, 41, 74, 76,  1,  3,  2])\n"
     ]
    }
   ],
   "source": [
    "# Turn string into list of longs\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return Variable(tensor)\n",
    "\n",
    "print(char_tensor('abcDEF-/132'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can assemble a pair of input and target tensors for training, from a random chunk. The input will be all characters up to the last, and the target will be all characters from the first. So if our chunk is \"abc\" the input will correspond to \"ab\" while the target is \"bc\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_training_set():    \n",
    "    chunk = text_generator.random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    del chunk\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([29, 17, 14,  ..., 28, 18, 28])\n",
      "tensor([17, 14, 27,  ..., 18, 28, 96])\n"
     ]
    }
   ],
   "source": [
    "inp, target = random_training_set()\n",
    "print(inp)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating\n",
    "\n",
    "To evaluate the network we will feed one character at a time, use the outputs of the network as a probability distribution for the next character, and repeat. To start generation we pass a priming string to start building up the hidden state, from which we then generate one character at a time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(decoder, prime_str='A', predict_len=100, temperature=0.8, test = False):\n",
    "    hidden = decoder.init_hidden().to(device)\n",
    "    prime_input = char_tensor(prime_str).to(device)\n",
    "    predicted = prime_str\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Use priming string to \"build up\" hidden state\n",
    "        for p in range(len(prime_str) - 1):\n",
    "            _, hidden = decoder(torch.tensor(prime_input[p]), hidden)\n",
    "\n",
    "        inp = prime_input[-1].to(device)\n",
    "        if not test:\n",
    "            for p in range(predict_len):\n",
    "                hidden = hidden.to(device)\n",
    "                inp = inp.to(device)\n",
    "                output, hidden = decoder(inp, hidden)\n",
    "                # Sample from the network as a multinomial distribution\n",
    "                output_dist = output.data.view(-1).div(temperature).exp()\n",
    "                top_i = torch.multinomial(output_dist, 1)[0]\n",
    "\n",
    "                # Add predicted character to string and use as next input\n",
    "                predicted_char = all_characters[top_i]\n",
    "                predicted += predicted_char\n",
    "                inp = char_tensor(predicted_char)\n",
    "        else:\n",
    "            for p in range(1000):\n",
    "                hidden = hidden.to(device)\n",
    "                inp = inp.to(device)\n",
    "                output, hidden = decoder(inp, hidden)\n",
    "                # Sample from the network as a multinomial distribution\n",
    "                output_dist = output.data.view(-1).div(temperature).exp()\n",
    "                top_i = torch.multinomial(output_dist, 1)[0]\n",
    "\n",
    "                # Add predicted character to string and use as next input\n",
    "                predicted_char = all_characters[top_i]\n",
    "                predicted += predicted_char\n",
    "                inp = char_tensor(predicted_char)\n",
    "            \n",
    "            while predicted_char != '\\n':\n",
    "                hidden = hidden.to(device)\n",
    "                inp = inp.to(device)\n",
    "                output, hidden = decoder(inp, hidden)\n",
    "                # Sample from the network as a multinomial distribution\n",
    "                output_dist = output.data.view(-1).div(temperature).exp()\n",
    "                top_i = torch.multinomial(output_dist, 1)[0]\n",
    "\n",
    "                # Add predicted character to string and use as next input\n",
    "                predicted_char = all_characters[top_i]\n",
    "                predicted += predicted_char\n",
    "                inp = char_tensor(predicted_char)\n",
    "                \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "A helper to print the amount of time passed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, math\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "    torch.cuda.empty_cache()\n",
    "    inp = inp.to(device)\n",
    "    target = target.to(device)\n",
    "    hidden = decoder.init_hidden().to(device)\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "    for c in range(len(inp)):\n",
    "        output, hidden = decoder(torch.tensor(inp[c]), hidden)\n",
    "        loss += criterion(output, torch.tensor(target[c]).reshape(1,))\n",
    "    del output\n",
    "    del hidden\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "    return loss / len(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the training parameters, instantiate the model, and start training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "print_every = 10\n",
    "plot_every = 10\n",
    "hidden_size = 100\n",
    "n_layers = 1\n",
    "lr = 0.005\n",
    "\n",
    "decoder = RNN(n_characters, hidden_size, n_characters, n_layers).to(device)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]C:\\Users\\ashis\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\ashis\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      " 10%|████████                                                                         | 10/100 [01:37<14:51,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1m 41s (10 10%) 2.8368]\n",
      "theto\n",
      "tes aricutepipin iomibpclil y icatd tifrole r ei mcol tn eaanitoide ctos elind osrmtresa  tirose \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▏                                                                | 20/100 [03:28<14:34, 10.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3m 31s (20 20%) 2.5737]\n",
      "thaistu an de timintre sed omompos aes aeceacbe sevenre f dr ata arphals ind tof ive ine ale ucondife  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▎                                                        | 30/100 [05:10<12:09, 10.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5m 13s (30 30%) 2.4428]\n",
      "thes\n",
      "g in edre pro\n",
      "site ofo mecen ce whe ser enof pratre as in ins olumire thing thes er ote ge deched \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████▍                                                | 40/100 [07:10<11:46, 11.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7m 13s (40 40%) 2.3232]\n",
      "the porcatle patine the ont puple co rqulith che th bulluto thecy in an pas ben harenacas vont darmith \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████▌                                        | 50/100 [08:53<08:20, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8m 56s (50 50%) 2.3006]\n",
      "th\n",
      "inly ase thon congesond urseder\n",
      "ricanne ll ainod ad ctions in of thentithe freont pronitis cecitamu \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████▌                                | 60/100 [10:43<07:08, 10.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10m 47s (60 60%) 2.2974]\n",
      "th preppkird innanged diang story row is stion anatiof thins pat\n",
      "and th the fredule derfowe stincyes u \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████▋                        | 70/100 [12:39<06:55, 13.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12m 42s (70 70%) 2.1629]\n",
      "thagity sinth anis of fore viated grpersus ther the ntrody\n",
      "of lins suteions om the fosing win lardde o \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████▊                | 80/100 [14:30<03:34, 10.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14m 34s (80 80%) 2.1252]\n",
      "tho of and shection condpant in to sow dical im moal cotired of of theal a ncantund the\n",
      "thate ca evion \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████▉        | 90/100 [16:29<01:59, 11.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16m 32s (90 90%) 2.1216]\n",
      "theer the and wo the cichoriomcting the eting preap digsia gendical insing winat in is ellined the sur \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [18:17<00:00, 10.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18m 20s (100 100%) 2.1338]\n",
      "thy the the for fretithe an were conce pared pectias indeilinurimit poutings padient lates actiect and \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, n_epochs + 1),position = 0, leave = True):\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    loss = train(*random_training_set())       \n",
    "    loss_avg += loss\n",
    "    \n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
    "        print(evaluate(decoder, 'th', 100), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0\n",
    "\n",
    "    del loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2abd7024cc8>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"loss\")\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashis\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the paria unimes and the omost mpuracin the cacts ad lester of the an exproult prodecall pecistais hudimatation ratibithe haticatiotind sof wan sedity frospe the in ponerres\n",
      "metiente ase deving of the precobled condual ssingerming tereated erarsere simese pobound con bulticentation ensule xes\n",
      "in the ral pry the asked is the on the conclads of tived coep fhigh thee paction uve dat the ansteulde eptatentared whloused beent the to pedichs con of predith an conin urabien\n",
      "on ifein houry jores ad iunt the of the wwels ass and cation the cont nachine the as prame the spreptral in the vew con mation pacifudithivealtion gfider psanith ensinodure sen pronte reed aluct dever depelentim as a and hecommentaning ang nemlatienact in con pourse ons wh githe covang of gent anymmorts povion whing patiest of a dlited the arvis the ve copithid19s providing iment emericos fredia he pacind sunina buction of in cospatien quent ay auchlme for sing replensers on cant and plonoty vosuch thed the the nowicating sons x encinastent action and the the and cang consctided\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(decoder, 'the', 100, test = True), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashis\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covided not and the in as\n",
      "te be ase mevide gan as onsto sombested cal consellg th the olle seal proulbus to we par strion sund the cont empoled of cal to dive contion of to pthid sto the fropormonte the ons or the ancin resille usts the the smon the neal sisradinat as ind that noculation allo cal pone pour purpersive als\n",
      "semetine suresic for stheris\n",
      "presing preme conclulmong fargely frotulat in nat in fromby an ser othe cont divining uswhow bent ant asse whl2 the cundicuced pepuzerge ond prower ding ferea for pation pesagne ins the esinicie sevice ore rain st undent rase the ping to ving umemest chagice are alathe to dection and the of as tovein sewush to an of antident edulilatis the in frute ensoper eve consuid dian paclome enthe entring aforerents for wigrose cotresk as selovinted thacit resemine the mall and in strespond arer is trourwite the the aucroprochin\n",
      "in the redeutiectiom mareseges celating an wis\n",
      "conperply of in here miduadice entataf vele and peran catibazary the mexsming comungls nely rich the of of mistents puthe in ensed concmuridiss the arving papewe deit\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(decoder, 'covid', 100, test = True), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashis\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hospitald pcequent of the swing drase\n",
      "and och of the the of chuty redatith ssemical recoplicing wice in afuing to the delience sorverche the are dentibu of th the otealitie the rges of medity atied font in costing vas datenterse eamizien a cedunge strodid suferned wical rebins the riseming on than the tbe kentera the vity pactiden infiter and to ne prontions and of trestealys prasiin of seghes the thes the amal to went pstromal dase whe ein shoraltys pero pactommation the and whroment in to of the pentomented of than sembins\n",
      "lou9g alcit oned the ch\n",
      "tude eselicerarice com micaride the virvipllited conss and stemen dith matenseres the mon celres in an to the the cctors ofr pabing prosy of dina inted progat wine ompted and the in urvial in qudy ule praceing prorcuss the whlis soplace of ranscoch of the ecal the sin tand the diter stin in the hecinars of to severitere seary afemoled in fronebligras\n",
      "so of re hor pals the sure rendacltay echecrent obrely of matuterneriepoonite the in there in rated us as commed the ofly theith arances consoutor forte vouris recents spandiate th mered racs molis an destion intiea sacto thee a premetire cored wan somitucacterased of prars on on revich opery in consist viarte fficteral crause proter the predice of the delsing tor beent oblcig the wents pontes\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(decoder, 'hospital', 100, test = True), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Due to computation limitations the model was not able train for more epochs, the results can be improved if we let the model train for around 500-750 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
